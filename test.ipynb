{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Label: 00000 là ko cầm tiền, còn lại là các mệnh giá\n",
    "label = \"00000\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Biến đếm, để chỉ lưu dữ liệu sau khoảng 60 frame, tránh lúc đầu chưa kịp cầm tiền lên\n",
    "i=0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    #\n",
    "    i+=1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    frame = cv2.resize(frame, dsize=None, fx=0.3,fy=0.3)\n",
    "\n",
    "    # Hiển thị\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    # Lưu dữ liệu\n",
    "    if i>=60:\n",
    "        print(\"Số ảnh capture = \", i-60)\n",
    "        # Tạo thư mục nếu chưa có\n",
    "        if not os.path.exists(DATA_PATH + str(label)):\n",
    "            os.mkdir(DATA_PATH + str(label))\n",
    "\n",
    "        cv2.imwrite(DATA_PATH + str(label) + \"/\" + str(i) + \".png\",frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "raw_folder = \"data/\"\n",
    "def save_data(raw_folder=raw_folder):\n",
    "\n",
    "    dest_size = (128, 128)\n",
    "    print(\"Bắt đầu xử lý ảnh...\")\n",
    "\n",
    "    pixels = []\n",
    "    labels = []\n",
    "\n",
    "    # Lặp qua các folder con trong thư mục raw\n",
    "    for folder in listdir(raw_folder):\n",
    "        if folder!='.DS_Store':\n",
    "            print(\"Folder=\",folder)\n",
    "            # Lặp qua các file trong từng thư mục chứa các em\n",
    "            for file in listdir(raw_folder  + folder):\n",
    "                if file!='.DS_Store':\n",
    "                    print(\"File=\", file)\n",
    "                    pixels.append( cv2.resize(cv2.imread(raw_folder  + folder +\"/\" + file), dsize=(128,128)))\n",
    "                    labels.append( folder)\n",
    "\n",
    "    pixels = np.array(pixels)\n",
    "    labels = np.array(labels)#.reshape(-1,1)\n",
    "\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    encoder = LabelBinarizer()\n",
    "    labels = encoder.fit_transform(labels)\n",
    "    print(labels)\n",
    "\n",
    "    file = open('pix.data', 'wb')\n",
    "    # dump information to that file\n",
    "    pickle.dump((pixels,labels), file)\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    file = open('pix.data', 'rb')\n",
    "\n",
    "    # dump information to that file\n",
    "    (pixels, labels) = pickle.load(file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "    print(pixels.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "\n",
    "    return pixels, labels\n",
    "\n",
    "#save_data()\n",
    "X,y = load_data()\n",
    "#random.shuffle(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "def get_model():\n",
    "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    # Dong bang cac layer\n",
    "    for layer in model_vgg16_conv.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Tao model\n",
    "    input = Input(shape=(128, 128, 3), name='image_input')\n",
    "    output_vgg16_conv = model_vgg16_conv(input)\n",
    "\n",
    "    # Them cac layer FC va Dropout\n",
    "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Compile\n",
    "    my_model = Model(inputs=input, outputs=x)\n",
    "    my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return my_model\n",
    "\n",
    "vggmodel = get_model()\n",
    "\n",
    "filepath=\"weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.1,\n",
    "    rescale=1./255,\n",
    "\twidth_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "\thorizontal_flip=True,\n",
    "    brightness_range=[0.2,1.5], fill_mode=\"nearest\")\n",
    "\n",
    "aug_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "vgghist=vggmodel.fit_generator(aug.flow(X_train, y_train, batch_size=64),\n",
    "                               epochs=50,# steps_per_epoch=len(X_train)//64,\n",
    "                               validation_data=aug.flow(X_test,y_test,\n",
    "                               batch_size=64),\n",
    "                               callbacks=callbacks_list)\n",
    "\n",
    "vggmodel.save(\"vggmodel.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    axs[0].plot(range(1, len(model_history.history[acc]) + 1), model_history.history[acc])\n",
    "    axs[0].plot(range(1, len(model_history.history[val_acc]) + 1), model_history.history[val_acc])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1, len(model_history.history[acc]) + 1), len(model_history.history[acc]) / 10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n",
    "    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1), len(model_history.history['loss']) / 10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    #plt.show()\n",
    "    plt.savefig('roc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.models import  load_model\n",
    "import sys\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Dinh nghia class\n",
    "class_name = ['00000','10000','20000','50000']\n",
    "\n",
    "def get_model():\n",
    "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    # Dong bang cac layer\n",
    "    for layer in model_vgg16_conv.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Tao model\n",
    "    input = Input(shape=(128, 128, 3), name='image_input')\n",
    "    output_vgg16_conv = model_vgg16_conv(input)\n",
    "\n",
    "    # Them cac layer FC va Dropout\n",
    "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Compile\n",
    "    my_model = Model(inputs=input, outputs=x)\n",
    "    my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return my_model\n",
    "\n",
    "# Load weights model da train\n",
    "my_model = get_model()\n",
    "my_model.load_weights(\"weights-19-1.00.hdf5\")\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    #\n",
    "\n",
    "    ret, image_org = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    image_org = cv2.resize(image_org, dsize=None,fx=0.5,fy=0.5)\n",
    "    # Resize\n",
    "    image = image_org.copy()\n",
    "    image = cv2.resize(image, dsize=(128, 128))\n",
    "    image = image.astype('float')*1./255\n",
    "    # Convert to tensor\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    predict = my_model.predict(image)\n",
    "    print(\"This picture is: \", class_name[np.argmax(predict[0])], (predict[0]))\n",
    "    print(np.max(predict[0],axis=0))\n",
    "    if (np.max(predict)>=0.8) and (np.argmax(predict[0])!=0):\n",
    "\n",
    "\n",
    "        # Show image\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        org = (50, 50)\n",
    "        fontScale = 1.5\n",
    "        color = (0, 255, 0)\n",
    "        thickness = 2\n",
    "\n",
    "        cv2.putText(image_org, class_name[np.argmax(predict)], org, font,\n",
    "                    fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Picture\", image_org)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (2, 3, 4)\n",
    "\n",
    "b = a[:2]\n",
    "\n",
    "type(b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "439a4a65f8220997985820a8da139527bf85fee5dfb1dd4c3c72bd937f9b027b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('money-classify')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
